{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from data.make_casting_graph import oneway_to_bidirected_graph\n",
    "from scipy.sparse import csc_matrix\n",
    "import time\n",
    "from pagerank import pagerank\n",
    "from sklearn.preprocessing import normalize\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create idx to num comments\n",
    "with open('./data/ratings.csv', encoding='utf-8') as f:\n",
    "    docs = [line.strip().split(',') for line in f.readlines()[1:]]\n",
    "    _idx2numcomments = {movie_idx:int(num) for num, movie_idx in docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre defined casting weight graph\n",
    "with open('./data/casting_graph.pkl', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create idx to actor name function\n",
    "with open('./data/actors.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    docs = [line.split(',') for line in f.readlines()[1:]]\n",
    "    # English name if exist else Korean name\n",
    "    _idx2actor = {doc[0]:doc[1] for doc in docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/movies.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    docs = [line.split(',') for line in f.readlines()[1:]]\n",
    "    _idx2movie = {doc[0]:doc[1] for doc in docs if len(docs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2movie = lambda idx: _idx2movie.get(idx, 'Unknown')\n",
    "idx2actor = lambda idx: _idx2actor.get(idx, 'Unknown')\n",
    "idx2numcomments = lambda idx: _idx2numcomments.get(idx,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = oneway_to_bidirected_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기생충 40\n",
      "극한직업 15\n",
      "마약왕 15\n",
      "인터스텔라 14\n",
      "어벤져스: 엔드게임 12\n",
      "걸캅스 12\n",
      "마녀 12\n",
      "택시운전사 11\n",
      "배심원들 11\n",
      "신과함께-죄와 벌 11\n"
     ]
    }
   ],
   "source": [
    "for movie in sorted(_idx2numcomments.items(), key=lambda x: x[1], reverse=True)[:10] :\n",
    "    print(idx2movie(movie[0]), movie[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(G):\n",
    "    \"\"\"It returns outbound normalized graph\n",
    "    Arguments\n",
    "    ---------\n",
    "    G: inbound graph dict of dict\n",
    "    \"\"\"\n",
    "    # Sum of outbound weight\n",
    "    # t: to node, f: from node, w: weight\n",
    "    W_sum = {}    \n",
    "    for t, f_dict in G.items():\n",
    "        for f, w in f_dict.items():\n",
    "            W_sum[f] = W_sum.get(f, 0) + w\n",
    "    A = {t:{f:w/W_sum[f] for f,w in f_dict.items()} for t, f_dict in G.items()}    \n",
    "    nodes = set(G.keys())\n",
    "    nodes.update(W_sum)\n",
    "    return A, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, bias=None, df=0.15,\n",
    "             max_iter=50, converge_error=0.001,verbose=0):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    G: Inbound graph, dict of dict\n",
    "        G[to_node][from_node] = weight (float)\n",
    "    df: damping factor, float. default 0.15\n",
    "    \"\"\"\n",
    "    \n",
    "    A, nodes = _normalize(G)\n",
    "    N = len(nodes) # number of nodes\n",
    "    sr = 1 - df # survival rate (1 -  damping factor)\n",
    "    ir = 1 / N # initial rank\n",
    "\n",
    "    # Initialization\n",
    "    rank = {n:ir for n in nodes}\n",
    "\n",
    "    # Initialization of bias\n",
    "    if not bias:\n",
    "        bias = {node:ir for node in nodes}\n",
    "\n",
    "    # Iteration\n",
    "    for _iter in range(1, max_iter + 1):\n",
    "        rank_new = {}\n",
    "\n",
    "        # t: to node, f: from node, w: weight\n",
    "        for t in nodes:\n",
    "            f_dict = A.get(t, {})\n",
    "            rank_t = sum((w*rank[f] for f, w in f_dict.items())) if f_dict else 0\n",
    "            rank_t = sr * rank_t + df * bias.get(t, 0)\n",
    "            rank_new[t] = rank_t\n",
    "\n",
    "        # convergence check\n",
    "        diff = sum((abs(rank[n] - rank_new[n]) for n in nodes))\n",
    "        if diff < converge_error:\n",
    "            if verbose:\n",
    "                print('Early stopped at iter = {}'.format(_iter))\n",
    "            break\n",
    "\n",
    "        if verbose:\n",
    "            sum_ = sum(rank_new.values())\n",
    "            print('Iteration = {}, diff = {}, sum = {}'.format(_iter, diff, sum_))\n",
    "\n",
    "        rank = rank_new\n",
    "\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = {node:(idx2numcomments(node.split()[1]) if node[0] == 'm' else 0) for node in g}\n",
    "_sum = sum(bias.values())\n",
    "bias = {node:b / _sum for node, b in bias.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1, diff = 0.6745935594038649, sum = 1.0000000000000067\n",
      "Iteration = 2, diff = 0.5133755765513079, sum = 1.0000000000000042\n",
      "Iteration = 3, diff = 0.4070843471025297, sum = 1.0000000000000075\n",
      "Iteration = 4, diff = 0.32881145690448793, sum = 1.0000000000000009\n",
      "Iteration = 5, diff = 0.26900006261697257, sum = 1.000000000000007\n",
      "Iteration = 6, diff = 0.22172923044566537, sum = 0.9999999999999926\n",
      "Iteration = 7, diff = 0.18372765496993088, sum = 0.9999999999999928\n",
      "Iteration = 8, diff = 0.1529064807765564, sum = 1.0000000000000049\n",
      "Iteration = 9, diff = 0.127563916243621, sum = 0.9999999999999911\n",
      "Iteration = 10, diff = 0.10676563571706423, sum = 0.9999999999999952\n",
      "Iteration = 11, diff = 0.08947335545631432, sum = 1.0000000000000075\n",
      "Iteration = 12, diff = 0.07517014319662835, sum = 1.0000000000000102\n",
      "Iteration = 13, diff = 0.0631852881114483, sum = 0.9999999999999936\n",
      "Iteration = 14, diff = 0.05320609097840679, sum = 0.9999999999999902\n",
      "Iteration = 15, diff = 0.044830477927067305, sum = 1.0000000000000082\n",
      "Iteration = 16, diff = 0.03781085146468677, sum = 1.000000000000007\n",
      "Iteration = 17, diff = 0.031912347290175926, sum = 1.0000000000000024\n",
      "Iteration = 18, diff = 0.026947257238086497, sum = 1.000000000000003\n",
      "Iteration = 19, diff = 0.022770184062896128, sum = 1.0000000000000075\n",
      "Iteration = 20, diff = 0.01924796744658091, sum = 1.0000000000000024\n",
      "Iteration = 21, diff = 0.016277037274941474, sum = 1.0000000000000002\n",
      "Iteration = 22, diff = 0.013770288868780624, sum = 0.9999999999999968\n",
      "Iteration = 23, diff = 0.011652758751255266, sum = 0.9999999999999987\n",
      "Iteration = 24, diff = 0.009864207584992407, sum = 1.0000000000000104\n",
      "Iteration = 25, diff = 0.008351860248971995, sum = 1.0000000000000042\n",
      "Iteration = 26, diff = 0.0070739230412209505, sum = 0.9999999999999988\n",
      "Iteration = 27, diff = 0.00599222271545739, sum = 1.0000000000000009\n",
      "Iteration = 28, diff = 0.005077294242177091, sum = 0.999999999999999\n",
      "Iteration = 29, diff = 0.0043028047100510634, sum = 0.9999999999999994\n",
      "Iteration = 30, diff = 0.003646940923353478, sum = 0.9999999999999934\n",
      "computation time : 0.8916201591491699 sec\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "dict_rank = pagerank(g, bias=bias, df=0.15, max_iter=30, converge_error=0.001, verbose=1)\n",
    "print('computation time : {} sec'.format(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161967, 기생충, 0.0032033878121671224\n",
      "167651, 극한직업, 0.0014303471787626468\n",
      "175322, 마녀, 0.0011565783119412997\n",
      "156464, 보헤미안 랩소디, 0.0011527961465662747\n",
      "130966, 부산행, 0.001098819013448319\n",
      "177483, 배심원들, 0.0009469824923736168\n",
      "174065, 걸캅스, 0.0009354687095915042\n",
      "37886, 클레멘타인, 0.000918249213245038\n",
      "154449, 리틀 포레스트, 0.00091821747845663\n",
      "163788, 알라딘, 0.0007997936563664337\n"
     ]
    }
   ],
   "source": [
    "movie_dict_rank = {node:dict_rank for node, dict_rank in dict_rank.items() if node[0].split()[0] == 'm'}\n",
    "    \n",
    "for movie in sorted(movie_dict_rank.items(), key=lambda x: x[1], reverse=True)[:10] :\n",
    "    movieId = movie[0].split()[1]\n",
    "    print('{}, {}, {}'.format(movieId, idx2movie(movieId), movie[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node index\n",
    "nodes = set(g.keys())\n",
    "idx2node = list(sorted(nodes))\n",
    "node2idx = {node:idx for idx, node in enumerate(idx2node)}\n",
    "\n",
    "#bias\n",
    "bias = np.array([b for node, b in sorted(bias.items(), key=lambda tp:node2idx[tp[0]])])\n",
    "\n",
    "#transform g to sparse matrix\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "for from_node, to_dict in g.items() :\n",
    "    from_idx = node2idx[from_node]\n",
    "    for to_node, weight in to_dict.items() :\n",
    "        to_idx = node2idx[to_node]\n",
    "        rows.append(from_idx)\n",
    "        cols.append(to_idx)\n",
    "        data.append(weight)\n",
    "    \n",
    "A = csc_matrix((data, (rows, cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 : diff = 0.1685245368865779\n",
      "iter 2 : diff = 0.123534416788289\n",
      "iter 3 : diff = 0.11717242074154521\n",
      "iter 4 : diff = 0.08676250638774644\n",
      "iter 5 : diff = 0.08106650827175174\n",
      "iter 6 : diff = 0.06044614044638538\n",
      "iter 7 : diff = 0.05589952786903922\n",
      "iter 8 : diff = 0.04188475454126574\n",
      "iter 9 : diff = 0.038452782327255894\n",
      "iter 10 : diff = 0.0289095171904886\n",
      "iter 11 : diff = 0.026405522194198443\n",
      "iter 12 : diff = 0.01994486388644759\n",
      "iter 13 : diff = 0.01811137289916391\n",
      "iter 14 : diff = 0.013753287448751986\n",
      "iter 15 : diff = 0.012408911428306675\n",
      "iter 16 : diff = 0.009469243738374537\n",
      "iter 17 : diff = 0.008494000468005527\n",
      "iter 18 : diff = 0.006511648928942716\n",
      "iter 19 : diff = 0.005809774127703195\n",
      "iter 20 : diff = 0.004473307017566352\n",
      "iter 21 : diff = 0.0039712967053357525\n",
      "iter 22 : diff = 0.0030704578506105173\n",
      "iter 23 : diff = 0.0027152845982687866\n",
      "iter 24 : diff = 0.002106149459828414\n",
      "iter 25 : diff = 0.0018577039374234091\n",
      "iter 26 : diff = 0.0014438021951808503\n",
      "iter 27 : diff = 0.0012704561426783514\n",
      "iter 28 : diff = 0.0009892576559651914\n",
      "iter 29 : diff = 0.0008685536766681317\n",
      "iter 30 : diff = 0.000677506241060136\n",
      "computation time : 0.02693033218383789 sec\n"
     ]
    }
   ],
   "source": [
    "max_iter = 30\n",
    "df = 0.85\n",
    "\n",
    "ir = 1/A.shape[0]\n",
    "num_rank = np.array([ir]*A.shape[0])\n",
    "\n",
    "starttime = time.time()\n",
    "for n_iter in range(1, max_iter + 1) :\n",
    "    rank_new = A.dot(num_rank) # call scipy.sparse safe_sparse_dot()\n",
    "    rank_new = normalize(rank_new.reshape(1,-1), norm='l1').reshape(-1)\n",
    "    rank_new = df * rank_new + (1-df) * bias\n",
    "    diff = abs(num_rank - rank_new).sum()\n",
    "    num_rank = rank_new\n",
    "    print('iter {} : diff = {}'.format(n_iter, diff))\n",
    "print('computation time : {} sec'.format(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161967, 기생충, 0.0015437432925532173\n",
      "156464, 보헤미안 랩소디, 0.0010864984266341052\n",
      "175322, 마녀, 0.0008946794759721638\n",
      "174065, 걸캅스, 0.0008564445054703045\n",
      "167651, 극한직업, 0.0007648489380972874\n",
      "37886, 클레멘타인, 0.000728929546919159\n",
      "157297, 마약왕, 0.0007133104346250872\n",
      "71509, 아저씨, 0.0006938076365826392\n",
      "136900, 어벤져스: 엔드게임, 0.0006567566198412949\n",
      "163788, 알라딘, 0.000638759850450271\n"
     ]
    }
   ],
   "source": [
    "#m_rank = {idx2movie[idx]:value for idx, value in enumerate(num_rank)}\n",
    "m_rank = {idx2node[idx]:node for idx, node in enumerate(num_rank)}\n",
    "movie_num_rank = {node:m_rank for node, m_rank in m_rank.items() if node[0] == 'm'}\n",
    "\n",
    "for movie in sorted(movie_num_rank.items(), key=lambda x: x[1], reverse=True)[:10] :\n",
    "    movieId = movie[0].split()[1]\n",
    "    print('{}, {}, {}'.format(movieId, idx2movie(movieId), movie[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame(sorted(movie_dict_rank.items(), key=lambda x: x[1], reverse=True)[:10], columns=['movie', 'weight'])\n",
    "movie_list = {node:g[node] for node in movie_df['movie']}\n",
    "movie_node = []\n",
    "\n",
    "neighbor_movie = {}\n",
    "\n",
    "for movie in movie_list.keys() :\n",
    "    actor_list = movie_list[movie]\n",
    "    n_movie_list = []\n",
    "    for actor in actor_list.keys() :\n",
    "        movie_node.append([movie.split()[1], actor.split()[1]])\n",
    "        neighbor_movie.update({actor.split()[1]:[node.split()[1] for node, movieId in g.items() if actor in movieId]})\n",
    "\n",
    "movie_node = pd.DataFrame(movie_node, columns=['movieId', 'actorId'])\n",
    "#movie_node.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_net = Network(height='750px', width='100%')\n",
    "dict_net.barnes_hut()\n",
    "dict_top_movie = movie_node['movieId']\n",
    "dict_targets = movie_node['actorId']\n",
    "\n",
    "edge_dict_data = zip(dict_top_movie, dict_targets)\n",
    "\n",
    "for dict_e in edge_dict_data :\n",
    "    src = dict_e[0]\n",
    "    dst = dict_e[1]\n",
    "    \n",
    "    dict_net.add_node(src, src, title=src)\n",
    "    dict_net.add_node(dst, dst, title=dst)\n",
    "    dict_net.add_edge(src, dst)\n",
    "    \n",
    "for dict_r in neighbor_movie :\n",
    "    dst_list = neighbor_movie[dict_r]\n",
    "    for dst in dst_list :\n",
    "        dict_net.add_node(dst, dst, title=dst)\n",
    "        dict_net.add_edge(dict_r, dst)\n",
    "        \n",
    "neighbor_map = dict_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in dict_net.nodes:\n",
    "    node[\"title\"] += \" Neighbors:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "    node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "dict_net.show(\"dict_node.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame(sorted(movie_num_rank.items(), key=lambda x: x[1], reverse=True)[:10], columns=['movie', 'weight'])\n",
    "movie_list = {node:g[node] for node in movie_df['movie']}\n",
    "movie_node = []\n",
    "\n",
    "neighbor_movie = {}\n",
    "\n",
    "for movie in movie_list.keys() :\n",
    "    actor_list = movie_list[movie]\n",
    "    for actor in actor_list.keys() :\n",
    "        movie_node.append([movie.split()[1], actor.split()[1]])\n",
    "        neighbor_movie.update({actor.split()[1]:[node.split()[1] for node, movieId in g.items() if actor in movieId]})\n",
    "    #for actor in movie.keys()\n",
    "\n",
    "movie_node = pd.DataFrame(movie_node, columns=['movieId', 'actorId'])\n",
    "#movie_node.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_net = Network(height='750px', width='100%')\n",
    "num_net.barnes_hut()\n",
    "num_top_movie = movie_node['movieId']\n",
    "num_targets = movie_node['actorId']\n",
    "\n",
    "edge_num_data = zip(num_top_movie, num_targets)\n",
    "\n",
    "for num_e in edge_num_data :\n",
    "    src = num_e[0]\n",
    "    dst = num_e[1]\n",
    "    \n",
    "    num_net.add_node(src, src, title=src)\n",
    "    num_net.add_node(dst, dst, title=dst)\n",
    "    num_net.add_edge(src, dst)\n",
    "    \n",
    "    \n",
    "for num_r in neighbor_movie :\n",
    "    dst_list = neighbor_movie[num_r]\n",
    "    for dst in dst_list :\n",
    "        num_net.add_node(dst, dst, title=dst)\n",
    "        num_net.add_edge(num_r, dst)\n",
    "    \n",
    "neighbor_map = num_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in num_net.nodes:\n",
    "    node[\"title\"] += \" Neighbors:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "    node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "num_net.show(\"num_node.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
